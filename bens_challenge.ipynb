{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 1.0 - A course by Jake Goldstein\n",
    "This is mostly a general idea of how to use python\n",
    "and about how to use dataframes and juypter notebooks.\n",
    "\n",
    "\n",
    "If you haven't already, make sure that you have pandas installed (need to run that in your terminal). Then feel free to import it. This will be important later on, and I will explain this later.\n",
    "- `pip install pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will let us use the [Pandas library](https://pandas.pydata.org/docs/reference/io.html)\n",
    "This is going to be our best friend for most of this guide.\n",
    "\n",
    "Note - we `import pandas as pd`. You don't have to do it like that if you don't want to, but that's how Simon did his pandas imports, so you know it must be right :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've made it this far, hopefully you have figured out a bit how Jupyter notebooks work.\n",
    "\n",
    "### Jupyter Notebooks\n",
    "Each little box here can be executed on its own. **To execute something, click that section and then click shift and enter at the same time.** \n",
    "\n",
    "What's really cool about notebooks, and probably the best thing, is I can import pandas (or do anything really), and then use it anywhere. Even if I mess something up really bad, because I only messed up that single block, everything will still work fine.\n",
    "For example, go ahead and run this next block, which, obviously, should fail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cisi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-c84c19881e4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcisi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cisi'"
     ]
    }
   ],
   "source": [
    "import cisi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you get a `ModuleNotFoundError`? Good. There's not a python package named `cisi`. Don't be ridiciulous. However, what's cool about these notebooks is that I can keep programming. This error isn't crashing my code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a cisi\n"
     ]
    }
   ],
   "source": [
    "print(\"I am a cisi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See! You can continue programming, even though you have an error that will normally bring Python to its knees.\n",
    "\n",
    "Something else worth noting about notebooks. Try typing stuff and hitting the tab button. It should be able to auto-complete some stuff for you which can be super helpful at times.\n",
    "\n",
    "### Python\n",
    "Next up, I want to talk breifly about python. Firstly, what version of Python are we running here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.5\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran this myself, I got 3.7.5. I'm not sure if that will be the same everytime, but this is a good thing to know. Python changes rather frequently, so knowing your exact version will help you know if things like this will work or not: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"how about this?\")? (<ipython-input-18-e0fb7d5f7af9>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-e0fb7d5f7af9>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print \"how about this?\"\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"how about this?\")?\n"
     ]
    }
   ],
   "source": [
    "print(\"does this work?\")\n",
    "print \"how about this?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the real hard-core peeps know that will work in Python 2. But don't you dare try that in Py3.\n",
    "\n",
    "There's really only a few things to know about Python (or any coding langauge) and I will really quickly review them here. Everything else is just sugar on top. (I assume you know what a variable is)\n",
    "1. The `if` statement (and `elif` and `else`)\n",
    "2. The `for` loop (and `while` loop)\n",
    "3. Functions (`return`s and all that jazz)\n",
    "\n",
    "#### If statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is true\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print(\"this is true\")\n",
    "else:\n",
    "    raise Exception(\"I am an error! Mwahaha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the above, the output you get will be `this is true`.\n",
    "\n",
    "Why?\n",
    "We asked if something is true, do something. In all other cases, do something else. The thing we checked in this case was just a value, True. It will always be true. Here's another perhaps slightly more interesting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is true\n"
     ]
    }
   ],
   "source": [
    "if 10 > 0:\n",
    "    print(\"this is true\")\n",
    "else:\n",
    "    raise Exception(\"I am an error! Mwahaha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also true. You're first challenge. Edit the above block so that you run the else section of code.\n",
    "#### For loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in (1, 2, 3, 4, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is some simple code. It will print whatever it is looping through. I is a variable that we are declaring that bassically says for each iteration of this loop take on the next value in the thing we are looping through.\n",
    "\n",
    "You can loop through anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "is\n",
      "some\n",
      "text\n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "s\n",
      "o\n",
      "m\n",
      "e\n",
      " \n",
      "t\n",
      "e\n",
      "x\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "for i in ('this', 'is', 'some', 'text'):\n",
    "    print(i)\n",
    "    \n",
    "for i in 'this is some text':\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops. You get the idea. \n",
    "\n",
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "max = -1\n",
    "for i in (1, 2, 3):\n",
    "    if i > max:\n",
    "        max = i\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple algorithm to get the max element in a list. We can do this for larger lists as well. Watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5431\n"
     ]
    }
   ],
   "source": [
    "max = -1\n",
    "for i in (100, 2, 45, 66, 5431, 5, 99, 26, 8, 8, 8, 22, 1645):\n",
    "    if i > max:\n",
    "        max = i\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer's are fast. But what's kinda annoying about this is that I had to type this all out a few times. What if I can just type this one, and the computer knows what I'm talking about. \n",
    "And now you get what a function is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(some_list_of_numbers):\n",
    "    # Please don't have negative numbers in the list\n",
    "    max = -1\n",
    "    for i in some_list_of_numbers:\n",
    "        if i > max:\n",
    "            max = i\n",
    "    return max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just defined a function! It takes some list of numbers and goes through it and will return the max number in the list. Watch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "5431\n"
     ]
    }
   ],
   "source": [
    "print(find_max((1, 2, 3)))\n",
    "print(find_max((100, 2, 45, 66, 5431, 5, 99, 26, 8, 8, 8, 22, 1645)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like last time! And that's it! Now you know how Python works. Everything is just sugar on top.\n",
    "\n",
    "#### Sugar on Top\n",
    "There are obviously a few things that I skipped (ask me about data-structures), but the point is, Python has tons of really cool built in stuff. \n",
    "\n",
    "But some of the best stuff isn't built in! What happens when I want to use someone else's code? Or some code that isn't built into python? `import`. This is a python thing where you say all that code that someone else wrote. Gimmie it. That's why we imported all that `pandas` stuff waaaay at the top. Now it's gonna come in handy.\n",
    "\n",
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file into dataframe\n",
    "df = pd.read_csv('my_coding_challenge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you forgot to import pandas, this will fail at this point. Go back and do everything again :)\n",
    "But if this did work, you now have something to play with. I made sure that `my_coding_challenge` was in the same folder (or directory) as I am in right now I can just import it straight here, nice and clean. \n",
    "\n",
    "We now have something called a dataframe (`df` for short). We can see it and play with it. Uncomment some of the stuff in this next block to try to get a feel for things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This entire block is commented out on purpose. It is just a warm up\n",
    "## See the df\n",
    "# print(df)\n",
    "## Get the type\n",
    "# print(type(df))\n",
    "## See all the functions that you can use\n",
    "# print(dir(df))\n",
    "## Get some meta-data about the columns\n",
    "# df.dtypes\n",
    "## Get all of one field from the df\n",
    "# df.channel_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of cool stuff that df's can do. Thanks Pandas!. Now let's do some mathy stuff with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>channel_view_count</th>\n",
       "      <th>channel_subscriber_count</th>\n",
       "      <th>channel_video_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.240017e+06</td>\n",
       "      <td>5.172437e+06</td>\n",
       "      <td>5.240017e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.209417e+07</td>\n",
       "      <td>2.022722e+05</td>\n",
       "      <td>5.934202e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.380357e+08</td>\n",
       "      <td>9.450692e+05</td>\n",
       "      <td>4.600393e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.856370e+06</td>\n",
       "      <td>1.660000e+04</td>\n",
       "      <td>5.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.799039e+06</td>\n",
       "      <td>3.690000e+04</td>\n",
       "      <td>1.430000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.966140e+07</td>\n",
       "      <td>1.156900e+05</td>\n",
       "      <td>3.740000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.261330e+11</td>\n",
       "      <td>1.550000e+08</td>\n",
       "      <td>1.067410e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       channel_view_count  channel_subscriber_count  channel_video_count\n",
       "count        5.240017e+06              5.172437e+06         5.240017e+06\n",
       "mean         5.209417e+07              2.022722e+05         5.934202e+02\n",
       "std          4.380357e+08              9.450692e+05         4.600393e+03\n",
       "min          0.000000e+00              0.000000e+00         0.000000e+00\n",
       "25%          1.856370e+06              1.660000e+04         5.100000e+01\n",
       "50%          5.799039e+06              3.690000e+04         1.430000e+02\n",
       "75%          1.966140e+07              1.156900e+05         3.740000e+02\n",
       "max          1.261330e+11              1.550000e+08         1.067410e+06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1A describe the dataset.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas will do all of the math for us. We don't honestly really care how it works. I am will to trust the community and say that the person who makes pandas just knows what they are doing. Here's some cool data. \n",
    "\n",
    "How do we deal with null data? `isnull` (and `isna` do the exact same thing) tells me if there are any values in my df that are null (True is they are null, false if they are not null). Any will tell me for all of these if any are True. This would happen if a row or something like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_id                  False\n",
      "stats_date                  False\n",
      "channel_view_count          False\n",
      "channel_subscriber_count    False\n",
      "channel_video_count         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# print(df.isna().any())\n",
    "print(df.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have some missing data points. How many? Good question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_id                  0\n",
      "stats_date                  0\n",
      "channel_view_count          0\n",
      "channel_subscriber_count    0\n",
      "channel_video_count         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will break-down how many of each field we are missing. Let's play around a bit with this to figure out how we want to deal with missing data points (i.e. null values). First, make a function to loop through something n number of times (we will be using this a bit). Note: the while loop (this is new to us)\n",
    "\n",
    "This function takes three parameters, s, x and n (perhaps we should be more verbose with our parameters to make our code more readable...) s is something that we want to iterate through. x is the first element we should start at. n is how many iterations of that thing we want to do.\n",
    "\n",
    "We give a default for x and n. x=0 and n=200. This means that we don't NEED to specify these variables if we don't want to. They are optional because they have defaults. s, however, is manditory. \n",
    "\n",
    "Food for thought: What happens if the thing we iterate though has fewer than n items? What happens if it has fewer than x items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_some(s, x=0, n=200):\n",
    "    while x < n:\n",
    "        print(s.get(x))\n",
    "        x = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's just see a sub-set of what we are working with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11100.0\n",
      "11100.0\n",
      "15900.0\n",
      "17500.0\n",
      "18400.0\n",
      "18600.0\n",
      "18500.0\n",
      "18500.0\n",
      "18400.0\n",
      "18300.0\n",
      "18300.0\n",
      "66240.0\n",
      "75200.0\n",
      "83400.0\n",
      "89200.0\n",
      "100000.0\n",
      "107000.0\n",
      "113000.0\n",
      "118000.0\n",
      "122000.0\n",
      "127000.0\n",
      "132000.0\n",
      "137000.0\n",
      "145000.0\n",
      "145000.0\n",
      "8060.0\n",
      "16000.0\n",
      "17900.0\n",
      "22400.0\n",
      "22400.0\n",
      "7536.0\n",
      "7800.0\n",
      "8030.0\n",
      "8280.0\n",
      "8530.0\n",
      "8900.0\n",
      "9250.0\n",
      "9780.0\n",
      "10000.0\n",
      "10500.0\n",
      "10800.0\n",
      "10800.0\n",
      "14400.0\n",
      "15000.0\n",
      "15600.0\n",
      "17200.0\n",
      "17900.0\n",
      "18900.0\n",
      "19500.0\n",
      "19500.0\n",
      "24700.0\n",
      "32600.0\n",
      "33300.0\n",
      "34500.0\n",
      "35600.0\n",
      "35600.0\n",
      "26000.0\n",
      "28500.0\n",
      "29600.0\n",
      "30600.0\n",
      "32000.0\n",
      "32000.0\n",
      "31800.0\n",
      "31900.0\n",
      "116928.0\n",
      "119000.0\n",
      "164000.0\n",
      "178000.0\n",
      "187000.0\n",
      "191000.0\n",
      "222000.0\n",
      "230000.0\n",
      "231000.0\n",
      "230000.0\n",
      "230000.0\n",
      "26600.0\n",
      "26500.0\n",
      "26500.0\n",
      "26500.0\n",
      "26400.0\n",
      "26400.0\n",
      "26400.0\n",
      "26300.0\n",
      "26300.0\n",
      "26200.0\n",
      "26200.0\n",
      "545754.0\n",
      "584000.0\n",
      "607000.0\n",
      "635000.0\n",
      "654000.0\n",
      "669000.0\n",
      "700000.0\n",
      "725000.0\n",
      "756000.0\n",
      "774000.0\n",
      "799000.0\n",
      "799000.0\n",
      "19784.0\n",
      "20100.0\n",
      "20100.0\n",
      "20000.0\n",
      "19900.0\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "19400.0\n",
      "19400.0\n",
      "26200.0\n",
      "26400.0\n",
      "26600.0\n",
      "27400.0\n",
      "27800.0\n",
      "28200.0\n",
      "28500.0\n",
      "29900.0\n",
      "29900.0\n",
      "139220.0\n",
      "144000.0\n",
      "153000.0\n",
      "159000.0\n",
      "166000.0\n",
      "179000.0\n",
      "185000.0\n",
      "189000.0\n",
      "195000.0\n",
      "204000.0\n",
      "204000.0\n",
      "39866.0\n",
      "39900.0\n",
      "40000.0\n",
      "40000.0\n",
      "40100.0\n",
      "40200.0\n",
      "40700.0\n",
      "40900.0\n",
      "41100.0\n",
      "41200.0\n",
      "41200.0\n",
      "56200.0\n",
      "58400.0\n",
      "60200.0\n",
      "65700.0\n",
      "68100.0\n",
      "70200.0\n",
      "73700.0\n",
      "78000.0\n",
      "78000.0\n",
      "12954.0\n",
      "13400.0\n",
      "14300.0\n",
      "14900.0\n",
      "15400.0\n",
      "15700.0\n",
      "15800.0\n",
      "16000.0\n",
      "16100.0\n",
      "16100.0\n",
      "16200.0\n",
      "16300.0\n",
      "16300.0\n",
      "77522.0\n",
      "77200.0\n",
      "77000.0\n",
      "76900.0\n",
      "76600.0\n",
      "76500.0\n",
      "75900.0\n",
      "75600.0\n",
      "75400.0\n",
      "75200.0\n",
      "75000.0\n",
      "74800.0\n",
      "384000.0\n",
      "384000.0\n",
      "383000.0\n",
      "383000.0\n",
      "382000.0\n",
      "381000.0\n",
      "381000.0\n",
      "380000.0\n",
      "379000.0\n",
      "379000.0\n",
      "15370.0\n",
      "15300.0\n",
      "15300.0\n",
      "15400.0\n",
      "15400.0\n",
      "15400.0\n",
      "15300.0\n",
      "15300.0\n",
      "15300.0\n",
      "15300.0\n",
      "15200.0\n",
      "15200.0\n",
      "15200.0\n",
      "12400.0\n",
      "12300.0\n",
      "12300.0\n"
     ]
    }
   ],
   "source": [
    "loop_through_some(df.channel_subscriber_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints the first 200 items in that series. I picked 200 randomly. If you scroll up a bit you'll notice there's some values that say `nan`. Nan is short for not a number - these are some of those values that we are missing. \n",
    "\n",
    "Worth noting that `nan` are really really weird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "print(math.nan == math.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we wanted to replace all of the `nan`'s with -1. We will take a copy of this because otherwise we will be changing data in our dataframe which we don't want to do yet for reasons you will see soon..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.channel_subscriber_count.copy()\n",
    "for i in range(len(s)):\n",
    "    # Check to see if the value is Nan\n",
    "    if math.isnan(s.get(i)):\n",
    "        s.loc[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20100.0\n",
      "20000.0\n",
      "19900.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "19400.0\n",
      "19400.0\n",
      "26200.0\n",
      "26400.0\n",
      "26600.0\n",
      "27400.0\n",
      "27800.0\n",
      "28200.0\n"
     ]
    }
   ],
   "source": [
    "# After some guess and check I found the nan's were in this range\n",
    "loop_through_some(s, x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila, that this worked! But this took a while. And these are pandas. Obviously there must be a better way to do this, right? Let's re-set s and try something new:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20100.0\n",
      "20000.0\n",
      "19900.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "19400.0\n",
      "19400.0\n",
      "26200.0\n",
      "26400.0\n",
      "26600.0\n",
      "27400.0\n",
      "27800.0\n",
      "28200.0\n"
     ]
    }
   ],
   "source": [
    "s = df.channel_subscriber_count.copy()\n",
    "s = s.replace(math.nan, -1)\n",
    "loop_through_some(s, x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That also worked! Can we do even better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20100.0\n",
      "20000.0\n",
      "19900.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "19400.0\n",
      "19400.0\n",
      "26200.0\n",
      "26400.0\n",
      "26600.0\n",
      "27400.0\n",
      "27800.0\n",
      "28200.0\n"
     ]
    }
   ],
   "source": [
    "s = df.channel_subscriber_count.copy()\n",
    "s = s.fillna(-1)\n",
    "loop_through_some(s, x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can! Don't forget, this is Panda land. Anything you can think of, someone has already done before.\n",
    "\n",
    "In fact, you'll notice above we don't even do this in such a clean way. Take a minute and think about what we are doing extra here!\n",
    "\n",
    "\n",
    "Hint - I mentioned it above...\n",
    "\n",
    "\n",
    "Need help still? The `copy`. We could actually change the series in place if we wanted to like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20100.0\n",
      "20000.0\n",
      "19900.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "19400.0\n",
      "19400.0\n",
      "26200.0\n",
      "26400.0\n",
      "26600.0\n",
      "27400.0\n",
      "27800.0\n",
      "28200.0\n"
     ]
    }
   ],
   "source": [
    "s = df.channel_subscriber_count.fillna(-1)\n",
    "loop_through_some(s, x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to make that change directly in the dataframe itself. What would that look like (I'm actually not sure if it's been changed or not at this point because Python's a bit confused with copying objects and what not...)\n",
    "\n",
    "Note: this looks a bit different than before. `df['channel_subscriber_count']` is the same as `df.channel_subscriber_count` (at least as far as I can tell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20100.0\n",
      "20000.0\n",
      "19900.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "-1.0\n",
      "19400.0\n",
      "19400.0\n",
      "26200.0\n",
      "26400.0\n",
      "26600.0\n",
      "27400.0\n",
      "27800.0\n",
      "28200.0\n"
     ]
    }
   ],
   "source": [
    "df['channel_subscriber_count'] = df['channel_subscriber_count'].fillna(-1)\n",
    "loop_through_some(df['channel_subscriber_count'], x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we wanted to do things a bit differently. At this point let's re-load the entire dataframe so we can mess around again with fresh data. What if, instead of changing the data to -1, we wanted to delete all lines where there was a `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5240017\n",
      "5240017\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('my_coding_challenge.csv')\n",
    "print(len(df))\n",
    "df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the heck! Does pandas have a bug? How can there be the same number of rows after we drop something? \n",
    "\n",
    "Pandas is smarter than you are. There isn't a bug. It's a safe gaurd. If you want to do something a little dangerous, something you might regret, sometimes pandas makes you say I mean it.\n",
    "\n",
    "Let's tell the dataframe we mean it this time.\n",
    "\n",
    "(Also just a reminder - IDK if this is actually the right way to deal with the nulls...it's just what I chose to do. There are lots of different options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5240017\n",
      "5172437\n"
     ]
    }
   ],
   "source": [
    "# 1B Handle Nulls\n",
    "print(len(df))\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next question we want to deal with is getting sub-sets of our giant data set. \n",
    "\n",
    "We actually already have seen one way to get a simple sub-set. We just select all of the rows from one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          UC---lM1j0uNzsFxF0V2IZnw\n",
      "1          UC---lM1j0uNzsFxF0V2IZnw\n",
      "2          UC--0iabXc55NqDGIR190lHg\n",
      "3          UC--0iabXc55NqDGIR190lHg\n",
      "4          UC--0iabXc55NqDGIR190lHg\n",
      "                     ...           \n",
      "5240012    UCzzz2DLFzyNReas9yHHJ_Bw\n",
      "5240013    UCzzz2DLFzyNReas9yHHJ_Bw\n",
      "5240014    UCzzz2DLFzyNReas9yHHJ_Bw\n",
      "5240015    UCzzz2DLFzyNReas9yHHJ_Bw\n",
      "5240016    UCzzz2DLFzyNReas9yHHJ_Bw\n",
      "Name: channel_id, Length: 5172437, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['channel_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like an okay place to start. Perhaps it would be a bit more helpful if we only had unique id's though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UC---lM1j0uNzsFxF0V2IZnw' 'UC--0iabXc55NqDGIR190lHg'\n",
      " 'UC--3c8RqSfAqYBdDjIG3UNA' ... 'UCzzoJY_ln_StRVdrRX1_ftg'\n",
      " 'UCzzp72CBMnkkduEWmRGBhnQ' 'UCzzz2DLFzyNReas9yHHJ_Bw']\n",
      "576820\n"
     ]
    }
   ],
   "source": [
    "unique_channel_ids = df['channel_id'].unique()\n",
    "print(unique_channel_ids)\n",
    "print(len(unique_channel_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we actually know one of the `channel_ids` I wonder if pandas will let us select data based off that id. Let's just take the first id in the list `'UC---lM1j0uNzsFxF0V2IZnw'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'UC---lM1j0uNzsFxF0V2IZnw'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/code/other/ben/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'UC---lM1j0uNzsFxF0V2IZnw'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-35604c94ba60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UC---lM1j0uNzsFxF0V2IZnw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/code/other/ben/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/code/other/ben/venv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'UC---lM1j0uNzsFxF0V2IZnw'"
     ]
    }
   ],
   "source": [
    "print(df['UC---lM1j0uNzsFxF0V2IZnw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hrrrmmmm. A `KeyError`. This means that I am trying to look something up that doesn't exist. It's like trying to find a made-up-word in the dictionary. You won't be able to find it.\n",
    "\n",
    "So we need to be looking up something that we know like `channel_id` and leveraging that. Almost similar to how we checked if each item in the series was a number or Nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UC---lM1j0uNzsFxF0V2IZnw\n",
      "True\n",
      "UC---lM1j0uNzsFxF0V2IZnw\n",
      "True\n",
      "UC--0iabXc55NqDGIR190lHg\n",
      "False\n",
      "UC--0iabXc55NqDGIR190lHg\n",
      "False\n",
      "UC--0iabXc55NqDGIR190lHg\n",
      "False\n",
      "UC--0iabXc55NqDGIR190lHg\n",
      "False\n",
      "UC--0iabXc55NqDGIR190lHg\n",
      "False\n",
      "UC--0iabXc55NqDGIR190lHg\n",
      "False\n",
      "UC--0iabXc55NqDGIR190lHg\n",
      "False\n",
      "UC--0iabXc55NqDGIR190lHg\n",
      "False\n",
      "UC--0iabXc55NqDGIR190lHg\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n",
      "UC--3c8RqSfAqYBdDjIG3UNA\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "s = df['channel_id']\n",
    "# This will loop through only the first 25 elements\n",
    "for i in s[:25]:\n",
    "    print(i)\n",
    "    if i == 'UC---lM1j0uNzsFxF0V2IZnw':\n",
    "        print(True)\n",
    "    else:\n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can check every row in a dataframe, and see if it's a row we are interested in. Kinda cool. But this is pandas. Of course there's a better way to make all of this happen. We can actually check inside a single call to see if the index is one that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           True\n",
      "1           True\n",
      "2          False\n",
      "3          False\n",
      "4          False\n",
      "           ...  \n",
      "5240012    False\n",
      "5240013    False\n",
      "5240014    False\n",
      "5240015    False\n",
      "5240016    False\n",
      "Name: channel_id, Length: 5172437, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df['channel_id'] == 'UC---lM1j0uNzsFxF0V2IZnw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this even a step further. We can get a sub-set of the dataframe where we only care about a certain `channel_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 channel_id  stats_date  channel_view_count  \\\n",
      "0  UC---lM1j0uNzsFxF0V2IZnw  2020-09-01              552376   \n",
      "1  UC---lM1j0uNzsFxF0V2IZnw  2020-10-01              554531   \n",
      "\n",
      "   channel_subscriber_count  channel_video_count  \n",
      "0                   11100.0                   16  \n",
      "1                   11100.0                   16  \n"
     ]
    }
   ],
   "source": [
    "print(df[df['channel_id'] == 'UC---lM1j0uNzsFxF0V2IZnw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we wanted to do something like this for every single channel_id, well no problem. Let's take this idea and just throw it into a loop. \n",
    "\n",
    "First let's get all the unique channel ids. Then lets print the sub-set of the datajust for the first two id's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 channel_id  stats_date  channel_view_count  \\\n",
      "0  UC---lM1j0uNzsFxF0V2IZnw  2020-09-01              552376   \n",
      "1  UC---lM1j0uNzsFxF0V2IZnw  2020-10-01              554531   \n",
      "\n",
      "   channel_subscriber_count  channel_video_count  \n",
      "0                   11100.0                   16  \n",
      "1                   11100.0                   16  \n",
      "                  channel_id  stats_date  channel_view_count  \\\n",
      "2   UC--0iabXc55NqDGIR190lHg  2019-12-01             2744868   \n",
      "3   UC--0iabXc55NqDGIR190lHg  2020-01-01             1654366   \n",
      "4   UC--0iabXc55NqDGIR190lHg  2020-02-01             1827834   \n",
      "5   UC--0iabXc55NqDGIR190lHg  2020-03-01                   0   \n",
      "6   UC--0iabXc55NqDGIR190lHg  2020-04-01                  74   \n",
      "7   UC--0iabXc55NqDGIR190lHg  2020-05-01                 546   \n",
      "8   UC--0iabXc55NqDGIR190lHg  2020-06-01                 735   \n",
      "9   UC--0iabXc55NqDGIR190lHg  2020-07-01                 648   \n",
      "10  UC--0iabXc55NqDGIR190lHg  2020-08-01                1062   \n",
      "\n",
      "    channel_subscriber_count  channel_video_count  \n",
      "2                    15900.0                   22  \n",
      "3                    17500.0                   35  \n",
      "4                    18400.0                   51  \n",
      "5                    18600.0                    0  \n",
      "6                    18500.0                    2  \n",
      "7                    18500.0                    2  \n",
      "8                    18400.0                    2  \n",
      "9                    18300.0                    0  \n",
      "10                   18300.0                    2  \n"
     ]
    }
   ],
   "source": [
    "unique_channel_ids = df['channel_id'].unique()\n",
    "for i in unique_channel_ids[:2]:\n",
    "#     print(df['channel_id'] == i)\n",
    "    print(df[df['channel_id'] == i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to see all of the dates from any one unique id! Let's take a look at all of the dates from a single unique id. In order to get a single `unique_channel_id` I'll introduce a new syntax.\n",
    "\n",
    "Remember, these are computers, so you start counting at 0, not at 1. So the first `unique_channel_ids` in the list is actually the `unique_channel_id` at index 0. Let's grab it and make a sub-set of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df[df['channel_id'] == unique_channel_ids[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can easily get the dates of this `channel_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2020-09-01\n",
      "1    2020-10-01\n",
      "Name: stats_date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(subset_df.stats_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can repeat this process for every single one of our `channel_ids`. Here's a small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2020-09-01\n",
      "1   2020-10-01\n",
      "Name: stats_date, dtype: datetime64[ns]\n",
      "2020-09   NaT\n",
      "2020-10   NaT\n",
      "Freq: M, Name: stats_date, dtype: datetime64[ns]\n",
      "2    2019-12-01\n",
      "3    2020-01-01\n",
      "4    2020-02-01\n",
      "5    2020-03-01\n",
      "6    2020-04-01\n",
      "7    2020-05-01\n",
      "8    2020-06-01\n",
      "9    2020-07-01\n",
      "10   2020-08-01\n",
      "Name: stats_date, dtype: datetime64[ns]\n",
      "2019-12   NaT\n",
      "2020-01   NaT\n",
      "2020-02   NaT\n",
      "2020-03   NaT\n",
      "2020-04   NaT\n",
      "2020-05   NaT\n",
      "2020-06   NaT\n",
      "2020-07   NaT\n",
      "2020-08   NaT\n",
      "Freq: M, Name: stats_date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "for i in unique_channel_ids[:2]:\n",
    "    subset = df[df['channel_id'] == i]\n",
    "    dates = pd.to_datetime(subset.stats_date)\n",
    "    print(dates)\n",
    "    date_range = pd.period_range(dates.min(), dates.max(), freq='M')\n",
    "    print(dates.reindex(date_range))\n",
    "#     dates == pd.period_range(dates[0], dates[len(dates)-1]\n",
    "#     start = dates[0]\n",
    "#     end = dates[len(subset)-1]\n",
    "#     print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
