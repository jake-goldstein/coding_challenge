{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 1.0 - A course by Jake Goldstein\n",
    "This is mostly a general idea of how to use python\n",
    "and about how to use dataframes and juypter notebooks.\n",
    "\n",
    "\n",
    "If you haven't already, make sure that you have pandas installed (need to run that in your terminal). Then feel free to import it. This will be important later on, and I will explain this later.\n",
    "- `pip install pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will let us use the [Pandas library](https://pandas.pydata.org/docs/reference/io.html)\n",
    "This is going to be our best friend for most of this guide.\n",
    "\n",
    "Note - we `import pandas as pd`. You don't have to do it like that if you don't want to, but that's how Simon did his pandas imports, so you know it must be right :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've made it this far, hopefully you have figured out a bit how Jupyter notebooks work.\n",
    "\n",
    "### Jupyter Notebooks\n",
    "Each little box here can be executed on its own. **To execute something, click that section and then click shift and enter at the same time.** \n",
    "\n",
    "What's really cool about notebooks, and probably the best thing, is I can import pandas (or do anything really), and then use it anywhere. Even if I mess something up really bad, because I only messed up that single block, everything will still work fine.\n",
    "For example, go ahead and run this next block, which, obviously, should fail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cisi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you get a `ModuleNotFoundError`? Good. There's not a python package named `cisi`. Don't be ridiciulous. However, what's cool about these notebooks is that I can keep programming. This error isn't crashing my code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I am a cisi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See! You can continue programming, even though you have an error that will normally bring Python to its knees.\n",
    "\n",
    "Something else worth noting about notebooks. Try typing stuff and hitting the tab button. It should be able to auto-complete some stuff for you which can be super helpful at times.\n",
    "\n",
    "### Python\n",
    "Next up, I want to talk breifly about python. Firstly, what version of Python are we running here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran this myself, I got 3.7.5. I'm not sure if that will be the same everytime, but this is a good thing to know. Python changes rather frequently, so knowing your exact version will help you know if things like this will work or not: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"does this work?\")\n",
    "print \"how about this?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the real hard-core peeps know that will work in Python 2. But don't you dare try that in Py3.\n",
    "\n",
    "There's really only a few things to know about Python (or any coding langauge) and I will really quickly review them here. Everything else is just sugar on top. (I assume you know what a variable is)\n",
    "1. The `if` statement (and `elif` and `else`)\n",
    "2. The `for` loop (and `while` loop)\n",
    "3. Functions (`return`s and all that jazz)\n",
    "\n",
    "#### If statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    print(\"this is true\")\n",
    "else:\n",
    "    raise Exception(\"I am an error! Mwahaha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the above, the output you get will be `this is true`.\n",
    "\n",
    "Why?\n",
    "We asked if something is true, do something. In all other cases, do something else. The thing we checked in this case was just a value, True. It will always be true. Here's another perhaps slightly more interesting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 10 > 0:\n",
    "    print(\"this is true\")\n",
    "else:\n",
    "    raise Exception(\"I am an error! Mwahaha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also true. You're first challenge. Edit the above block so that you run the else section of code.\n",
    "#### For loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (1, 2, 3, 4, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is some simple code. It will print whatever it is looping through. I is a variable that we are declaring that bassically says for each iteration of this loop take on the next value in the thing we are looping through.\n",
    "\n",
    "You can loop through anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ('this', 'is', 'some', 'text'):\n",
    "    print(i)\n",
    "    \n",
    "for i in 'this is some text':\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops. You get the idea. \n",
    "\n",
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = -1\n",
    "for i in (1, 2, 3):\n",
    "    if i > max:\n",
    "        max = i\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple algorithm to get the max element in a list. We can do this for larger lists as well. Watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = -1\n",
    "for i in (100, 2, 45, 66, 5431, 5, 99, 26, 8, 8, 8, 22, 1645):\n",
    "    if i > max:\n",
    "        max = i\n",
    "print(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer's are fast. But what's kinda annoying about this is that I had to type this all out a few times. What if I can just type this one, and the computer knows what I'm talking about. \n",
    "And now you get what a function is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(some_list_of_numbers):\n",
    "    # Please don't have negative numbers in the list\n",
    "    max = -1\n",
    "    for i in some_list_of_numbers:\n",
    "        if i > max:\n",
    "            max = i\n",
    "    return max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just defined a function! It takes some list of numbers and goes through it and will return the max number in the list. Watch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_max((1, 2, 3)))\n",
    "print(find_max((100, 2, 45, 66, 5431, 5, 99, 26, 8, 8, 8, 22, 1645)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like last time! And that's it! Now you know how Python works. Everything is just sugar on top.\n",
    "\n",
    "#### Sugar on Top\n",
    "There are obviously a few things that I skipped (ask me about data-structures), but the point is, Python has tons of really cool built in stuff. \n",
    "\n",
    "But some of the best stuff isn't built in! What happens when I want to use someone else's code? Or some code that isn't built into python? `import`. This is a python thing where you say all that code that someone else wrote. Gimmie it. That's why we imported all that `pandas` stuff waaaay at the top. Now it's gonna come in handy.\n",
    "\n",
    "### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file into dataframe\n",
    "df = pd.read_csv('my_coding_challenge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you forgot to import pandas, this will fail at this point. Go back and do everything again :)\n",
    "But if this did work, you now have something to play with. I made sure that `my_coding_challenge` was in the same folder (or directory) as I am in right now I can just import it straight here, nice and clean. \n",
    "\n",
    "We now have something called a dataframe (`df` for short). We can see it and play with it. Uncomment some of the stuff in this next block to try to get a feel for things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This entire block is commented out on purpose. It is just a warm up\n",
    "## See the df\n",
    "# print(df)\n",
    "## Get the type\n",
    "# print(type(df))\n",
    "## See all the functions that you can use\n",
    "# print(dir(df))\n",
    "## Get some meta-data about the columns\n",
    "# df.dtypes\n",
    "## Get all of one field from the df\n",
    "# df.channel_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of cool stuff that df's can do. Thanks Pandas!. Now let's do some mathy stuff with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1A describe the dataset.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas will do all of the math for us. We don't honestly really care how it works. I am will to trust the community and say that the person who makes pandas just knows what they are doing. Here's some cool data. \n",
    "\n",
    "How do we deal with null data? `isnull` (and `isna` do the exact same thing) tells me if there are any values in my df that are null (True is they are null, false if they are not null). Any will tell me for all of these if any are True. This would happen if a row or something like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.isna().any())\n",
    "print(df.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have some missing data points. How many? Good question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will break-down how many of each field we are missing. Let's play around a bit with this to figure out how we want to deal with missing data points (i.e. null values). First, make a function to loop through something n number of times (we will be using this a bit). Note: the while loop (this is new to us)\n",
    "\n",
    "This function takes three parameters, s, x and n (perhaps we should be more verbose with our parameters to make our code more readable...) s is something that we want to iterate through. x is the first element we should start at. n is how many iterations of that thing we want to do.\n",
    "\n",
    "We give a default for x and n. x=0 and n=200. This means that we don't NEED to specify these variables if we don't want to. They are optional because they have defaults. s, however, is manditory. \n",
    "\n",
    "Food for thought: What happens if the thing we iterate though has fewer than n items? What happens if it has fewer than x items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_some(s, x=0, n=200):\n",
    "    while x < n:\n",
    "        print(s.get(x))\n",
    "        x = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's just see a sub-set of what we are working with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop_through_some(df.channel_subscriber_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This prints the first 200 items in that series. I picked 200 randomly. If you scroll up a bit you'll notice there's some values that say `nan`. This happens when we import the csv file but there is something wrong. It's like when columns are missing from an excel file.\n",
    "\n",
    "Python has a hard time telling you that you are missing some cells though. Instead, it will tell you that you have `Nan`. Nan is short for 'not a number'. Any time in our output we see something like `Nan`, this is talking about some of those values that are missing.\n",
    "\n",
    "Worth noting that `nan` are really really weird:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we keep going, now I think is a good time to talk about `imports` a bit more. \n",
    "\n",
    "#### Imports\n",
    "Let's say that we wanted to to know 5! (remember, 5! (5 factorial) is 5 * 4 * 3 * 2 * 1). We can make a function to do that for us. Let's call it factorial and have it take a number n as a parameter. It will start at 1 and multiply all of the numbers from 1 until n, and return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    x = 1\n",
    "    result = 1\n",
    "    while x <= n:\n",
    "        result = result * x\n",
    "        x = x + 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's try this out. 5! should be 5 * 4 * 3 * 2 * 1 = 120. How'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(factorial(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can't be the first people to ever think that we might need this function. This is Python and coding and...common. Someone must have done this before us.\n",
    "\n",
    "And of course, someone has. If we want to be able to use their code we need to import it. Just like we imported pandas. Let's go ahead and `import math` now.https://docs.python.org/3/library/math.html#math.factorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know get all of the funcionality of `math`. For some things, the more obvious things, they are built into python in something called the [python standard library](https://docs.python.org/3/library/). These are all libraries that you can access from python anywhere, as long as you remember to import it.\n",
    "\n",
    "Some things that live in the python standard libraries are `os` to mess around with the operating system. `csv` to mess around with csv files. `datetime` to mess around with dates and times. It goes on and on and all of it is good and helpful, but perhaps most importantly, they are reliable.\n",
    "\n",
    "Let's take a peek at some of the built in stuff that math gives us using the built in `dir` function. (`dir` allows you to see all of the functions that you can call on a given object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(math))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see some obvious stuff like `pi`. Some trig stuff like `sin` and `tan`. Some good math operations like `pow` and `sqrt`. We also see `factorial`. Let's try that out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.factorial(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing, way less code. Not bad, right!\n",
    "\n",
    "You might have noticed that `pandas` is not in the list of standard python libraries. Good eye. `Pandas` is a library that someone else wrote and said anyone who wants to use it, go for it. They made it public. You can import it into your code by using an import statement. You just need to remember to install it first. `pandas`, as they say, does not come batties included with Python. \n",
    "\n",
    "When I install external Python libraries, I use `pip`. If you made it this far you already have used `pip`, you just might not have seen it. When you ran `make install` that installed a whole bunch of stuff, like `pandas` and `jupyter`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our math example now. You might see something that got us started on this entire `import` tangent. The dirty dirty `nan` stuff. As we were saying above, `nan` is something that is not a number. It happens when you try to read an excel sheet but are missing some columns for certain rows. Let's take a look at some `nan` stuff from the math library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.nan)\n",
    "print(type(math.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird - `nan` is a float. Can we add things to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.nan + 5.1)\n",
    "print(math.nan + 5)\n",
    "print(math.nan - 100)\n",
    "print(math.nan * 100)\n",
    "print(math.nan + math.nan)\n",
    "print(math.nan > 100)\n",
    "print(math.nan < 100)\n",
    "print(math.nan == 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAT. Something super weird is up with `nan`. You try to add stuff to it or do any math operation and it says just `nan`. You try to see if it's bigger, smaller or equal to 100, and everything it gives you is False. Can we convert it to an int?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int(math.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently not. `nan` is a stubborn beast.\n",
    "\n",
    "I wonder if `nan` == `nan`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.nan == math.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAT! I can't deal with these `nan`'s. Let try to replace every single ugly `nan` in our dataset with -1. -1 is resonable, `nan` is not.\n",
    "\n",
    "We will take a copy of our `channel_subscriber_count` in order to do this. This is because otherwise we will be changing data in our dataframe which we don't want to do yet for reasons you will see soon..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.channel_subscriber_count.copy()\n",
    "for i in range(len(s)):\n",
    "    # Check to see if the value is Nan\n",
    "    if math.isnan(s.get(i)):\n",
    "        s.loc[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After some guess and check I found the nan's were in this range\n",
    "loop_through_some(s, x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila, that this worked! But this took a while for that code to run. And these are pandas. Obviously there must be a better way to do this, right? Let's re-set s and try something new. The replace function. This will take any value, and replace it with any other value. Let's try replacing `nan` with -1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.channel_subscriber_count.copy()\n",
    "s = s.replace(math.nan, -1)\n",
    "loop_through_some(s, x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That also worked! Can we do even better? \n",
    "\n",
    "Of course we can! Don't forget, this is Panda land. Anything you can think of, someone has already done before.\n",
    "\n",
    "There is a special function called `fillna` that is used to fill `nan` (sometimes known as `na`) with any value you want. Let try replacing our `nan`'s this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.channel_subscriber_count.copy()\n",
    "s = s.fillna(-1)\n",
    "loop_through_some(s, x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, you'll notice above we don't even do this in such a clean way. Take a minute and think about what we are doing extra here!\n",
    "\n",
    "\n",
    "Hint - I mentioned it above...\n",
    "\n",
    "\n",
    "Need help still? The `copy`. We could actually change the series in place if we wanted to like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df.channel_subscriber_count.fillna(-1)\n",
    "loop_through_some(s, x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This changes the data directly in the series itself. The copy was changing the data inside a copy of the series.\n",
    "\n",
    "What if we wanted to make that change directly in the **dataframe** itself. What would that look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.channel_subscriber_count = df.channel_subscriber_count.fillna(-1)\n",
    "loop_through_some(df.channel_subscriber_count, x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's actually more than one way to do the exact same thing in pandas. The syntax will look a bit different than before. But, as far as I can tell at least, it is the exact same thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['channel_subscriber_count'] = df['channel_subscriber_count'].fillna(-1)\n",
    "loop_through_some(df['channel_subscriber_count'], x=100, n=115)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we wanted to do things a bit differently. What if, instead of changing the data to -1, we wanted to delete all lines where there was a `nan`. There's, natrually, a function for that. We can call `dropna` which will drop all `na`'s (`nan`'s)\n",
    "\n",
    "At this point let's re-load the entire dataframe so we can mess around again with fresh data with all of the `nan`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('my_coding_challenge.csv')\n",
    "print(len(df))\n",
    "df.dropna()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait! What the heck! Does pandas have a bug? How can there be the same number of rows after we drop something? \n",
    "\n",
    "Let's double check that there are actually any `nan`'s in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worry not. Pandas is just smarter than you are. \n",
    "\n",
    "There isn't a bug. \n",
    "\n",
    "It's a safe gaurd. \n",
    "\n",
    "If you want to do something a little dangerous, like dropping a ton of rows, something you might regret, sometimes pandas makes you say I mean it.\n",
    "\n",
    "Let's tell the dataframe we mean it this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1B Handle Nulls\n",
    "print(len(df))\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey! We did it! We got rid of all of those nasty `nan`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next question we want to deal with is getting sub-sets of our giant data set. \n",
    "\n",
    "We actually already have seen one way to get a simple sub-set. We just select all of the rows from one column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['channel_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like an okay place to start. Perhaps it would be a bit more helpful if we only had unique id's though. Luckily pandas can deal with that for us already by asking for just unique items from a series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_channel_ids = df['channel_id'].unique()\n",
    "print(unique_channel_ids)\n",
    "print(len(unique_channel_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we actually know one of the `channel_ids` I wonder if pandas will let us select data based off that id. Let's just take the first id in the list `'UC---lM1j0uNzsFxF0V2IZnw'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['UC---lM1j0uNzsFxF0V2IZnw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hrrrmmmm. A `KeyError`. This means that I am trying to look something up that doesn't exist. It's like trying to find a made-up-word in the dictionary. You won't be able to find it.\n",
    "\n",
    "So we need to be looking up something that we know like `channel_id` and leveraging that. Almost similar to how we checked if each item in the series was a number or Nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df['channel_id']\n",
    "# This will loop through only the first 25 elements\n",
    "for i in s[:25]:\n",
    "    print(i)\n",
    "    if i == 'UC---lM1j0uNzsFxF0V2IZnw':\n",
    "        print(True)\n",
    "    else:\n",
    "        print(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can check every row in a dataframe, and see if it's a row we are interested in. Kinda cool. But this is pandas. Of course there's a better way to make all of this happen. We can actually check inside a single call to see if the index is one that we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['channel_id'] == 'UC---lM1j0uNzsFxF0V2IZnw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this even a step further. We can get a sub-set of the dataframe where we only care about a certain `channel_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['channel_id'] == 'UC---lM1j0uNzsFxF0V2IZnw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we wanted to do something like this for every single channel_id, well no problem. Let's take this idea and just throw it into a loop. \n",
    "\n",
    "First let's get all the unique channel ids. Then lets print the sub-set of the datajust for the first two id's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_channel_ids = df['channel_id'].unique()\n",
    "\n",
    "# Only loop thorugh the first two unique channel id's\n",
    "for i in unique_channel_ids[:2]:\n",
    "    print(df[df['channel_id'] == i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to see all of the dates from any one unique id! Let's take a look at all of the dates from a single unique id. In order to get a single `unique_channel_id` I'll introduce a new syntax.\n",
    "\n",
    "Remember, these are computers, so you start counting at 0, not at 1. So the first `unique_channel_ids` in the list is actually the `unique_channel_id` at index 0. Let's grab it and make a sub-set of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df[df['channel_id'] == unique_channel_ids[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can easily get the dates of this `channel_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subset_df.stats_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can repeat this process for every single one of our `channel_ids`. Here's a small example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "for i in unique_channel_ids[:2]:\n",
    "    subset = df[df['channel_id'] == i]\n",
    "    dates = pd.to_datetime(subset.stats_date)\n",
    "    print(dates)\n",
    "    date_range = pd.period_range(dates.min(), dates.max(), freq='M')\n",
    "    print(dates.reindex(date_range))\n",
    "#     dates == pd.period_range(dates[0], dates[len(dates)-1]\n",
    "#     start = dates[0]\n",
    "#     end = dates[len(subset)-1]\n",
    "#     print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
